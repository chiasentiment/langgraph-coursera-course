{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "def reduce_messages(left: list[AnyMessage], right: list[AnyMessage]):\n",
    "    for message in right:\n",
    "        if not message.id:\n",
    "            message.id = str(uuid4())\n",
    "    merged = left.copy()\n",
    "    for message in right:\n",
    "        for i, existing in enumerate(merged):\n",
    "            if existing.id == message.id:\n",
    "                merged[i]=message\n",
    "                break\n",
    "        else:\n",
    "            merged.append(message)\n",
    "    return merged\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], reduce_messages]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system= \"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.execute_action)\n",
    "        graph.add_conditional_edges(\"llm\",\n",
    "                                    self.action_exists,\n",
    "                                    {True:\"action\", False: END})\n",
    "        graph.add_edge(\"action\",\"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer,\n",
    "                                   interrupt_before=['action'])\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "    def action_exists(self, messages: AgentState):\n",
    "        tool_calls = messages['messages'][-1].tool_calls\n",
    "        return(len(tool_calls)>0)\n",
    "    def call_openai(self, messages: AgentState):\n",
    "        messages = messages['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)]+messages\n",
    "        response = self.model.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    def execute_action(self, messages: AgentState):\n",
    "        tool_calls = messages['messages'][-1].tool_calls\n",
    "        responses = []\n",
    "        for t in tool_calls:\n",
    "            print (\"Invoking tools {t}\")\n",
    "            response = self.tools[t['name']].invoke(t['args'])\n",
    "            responses.append(ToolMessage(tool_call_id=t[\"id\"], name= t['name'], content=str(response)))\n",
    "        print (\"Back to LLM\") \n",
    "        return {\"messages\": responses} \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "abot = Agent(model=model, tools=[tool], checkpointer=memory, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Mpa2YQnkCXs6KeNChHUbE6iG', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 152, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5f052fb9-9b1b-4450-a4ad-682ccdbd0a70-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_Mpa2YQnkCXs6KeNChHUbE6iG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 22, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Whats the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Whats the weather in SF?', additional_kwargs={}, response_metadata={}, id='f6ecb2e1-bc77-4960-9180-62ca11040ed2'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Mpa2YQnkCXs6KeNChHUbE6iG', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 152, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5f052fb9-9b1b-4450-a4ad-682ccdbd0a70-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_Mpa2YQnkCXs6KeNChHUbE6iG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 22, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=('action',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0011fc-b70c-6b8c-8001-c991ff26735a'}}, metadata={'source': 'loop', 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Mpa2YQnkCXs6KeNChHUbE6iG', 'function': {'arguments': '{\"query\":\"weather in San Francisco\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 152, 'total_tokens': 174, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-5f052fb9-9b1b-4450-a4ad-682ccdbd0a70-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in San Francisco'}, 'id': 'call_Mpa2YQnkCXs6KeNChHUbE6iG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 152, 'output_tokens': 22, 'total_tokens': 174, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'thread_id': '1', 'step': 1, 'parents': {}}, created_at='2025-03-14T22:00:51.726607+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0011fc-b0d5-6e1c-8000-639c9cb0fac0'}}, tasks=(PregelTask(id='0091590e-6fad-4a07-f32e-c6318c19b8bb', name='action', path=('__pregel_pull', 'action'), error=None, interrupts=(), state=None, result=None),))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.graph.get_state(thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('action',)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abot.graph.get_state(thread).next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking tools {t}\n",
      "Back to LLM\n",
      "{'messages': [ToolMessage(content='[{\\'title\\': \\'Weather in San Francisco\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.775, \\'lon\\': -122.4183, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1741989659, \\'localtime\\': \\'2025-03-14 15:00\\'}, \\'current\\': {\\'last_updated_epoch\\': 1741989600, \\'last_updated\\': \\'2025-03-14 15:00\\', \\'temp_c\\': 13.9, \\'temp_f\\': 57.0, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 22.6, \\'wind_kph\\': 36.4, \\'wind_degree\\': 280, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1010.0, \\'pressure_in\\': 29.83, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 67, \\'cloud\\': 75, \\'feelslike_c\\': 11.4, \\'feelslike_f\\': 52.4, \\'windchill_c\\': 8.8, \\'windchill_f\\': 47.9, \\'heatindex_c\\': 11.7, \\'heatindex_f\\': 53.0, \\'dewpoint_c\\': 8.3, \\'dewpoint_f\\': 46.9, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 3.4, \\'gust_mph\\': 30.2, \\'gust_kph\\': 48.5}}\", \\'score\\': 0.9022356}, {\\'title\\': \\'San Francisco weather in March 2025 | Weather25.com\\', \\'url\\': \\'https://www.weather25.com/north-america/usa/california/san-francisco?page=month&month=March\\', \\'content\\': \\'San Francisco weather in March 2025 | Weather25.com San Francisco weather in March 2025 | San Francisco in March | Temperatures in San Francisco in March Weather in San Francisco in March - FAQ The average temperature in San Francisco in March is 8/17° C. On average, there are 5 rainy days in San Francisco during March. The weather in San Francisco in March is good. On average, there are 0 snowy days in San Francisco in March. More about the weather in San Francisco San Francisco 14 day weather Long range weather for San Francisco San Francisco weather in November San Francisco weather in December San Francisco Webcam Weather tomorrow Hotels in San Francisco\\', \\'score\\': 0.86767644}]', name='tavily_search_results_json', id='fbc43e8b-5c64-4e33-b3c1-d171ab955811', tool_call_id='call_Mpa2YQnkCXs6KeNChHUbE6iG')]}\n",
      "{'messages': [AIMessage(content='The current weather in San Francisco is partly cloudy with a temperature of 57.0°F (13.9°C). The wind speed is 36.4 km/h coming from the west. The humidity is at 67%, and the visibility is 9.0 miles.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 812, 'total_tokens': 870, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1b954966-dfda-4118-a272-35415aa4267c-0', usage_metadata={'input_tokens': 812, 'output_tokens': 58, 'total_tokens': 870, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream(None, thread):\n",
    "    for v in event.values():\n",
    "        print (v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(\"How many IPL teams are there and who won it last time and who are the favourites this year. What was the playing eleven for the defending champions?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ZIbUWbZlnEeUPqtH5dyQdzDc', 'function': {'arguments': '{\"query\": \"Number of IPL teams\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_QeLQG2Q5nD19Mi3kVumivsfC', 'function': {'arguments': '{\"query\": \"Current IPL champions\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_lfY1OrCluBHCjQlCaWw7Hlcv', 'function': {'arguments': '{\"query\": \"Favourites for IPL 2022\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_dME6cFdKRy1YqKhCC9rqYeSG', 'function': {'arguments': '{\"query\": \"Playing eleven for IPL defending champions\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 176, 'total_tokens': 280, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b41f23c5-7a7b-404d-ad74-30126b5709b1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Number of IPL teams'}, 'id': 'call_ZIbUWbZlnEeUPqtH5dyQdzDc', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Current IPL champions'}, 'id': 'call_QeLQG2Q5nD19Mi3kVumivsfC', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Favourites for IPL 2022'}, 'id': 'call_lfY1OrCluBHCjQlCaWw7Hlcv', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Playing eleven for IPL defending champions'}, 'id': 'call_dME6cFdKRy1YqKhCC9rqYeSG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 104, 'total_tokens': 280, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "()\n",
      "StateSnapshot(values={'messages': [HumanMessage(content='How many IPL teams are there and who won it last time and who are the favourites this year. What was the playing eleven for the defending champions?', additional_kwargs={}, response_metadata={}, id='e5a4b05e-1d91-4252-ba08-a65f14ce0a8d'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ZIbUWbZlnEeUPqtH5dyQdzDc', 'function': {'arguments': '{\"query\": \"Number of IPL teams\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_QeLQG2Q5nD19Mi3kVumivsfC', 'function': {'arguments': '{\"query\": \"Current IPL champions\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_lfY1OrCluBHCjQlCaWw7Hlcv', 'function': {'arguments': '{\"query\": \"Favourites for IPL 2022\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_dME6cFdKRy1YqKhCC9rqYeSG', 'function': {'arguments': '{\"query\": \"Playing eleven for IPL defending champions\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 176, 'total_tokens': 280, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b41f23c5-7a7b-404d-ad74-30126b5709b1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Number of IPL teams'}, 'id': 'call_ZIbUWbZlnEeUPqtH5dyQdzDc', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Current IPL champions'}, 'id': 'call_QeLQG2Q5nD19Mi3kVumivsfC', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Favourites for IPL 2022'}, 'id': 'call_lfY1OrCluBHCjQlCaWw7Hlcv', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Playing eleven for IPL defending champions'}, 'id': 'call_dME6cFdKRy1YqKhCC9rqYeSG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 104, 'total_tokens': 280, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=('action',), config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0011fc-e1b3-63c1-8001-902617614fc6'}}, metadata={'source': 'loop', 'writes': {'llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ZIbUWbZlnEeUPqtH5dyQdzDc', 'function': {'arguments': '{\"query\": \"Number of IPL teams\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_QeLQG2Q5nD19Mi3kVumivsfC', 'function': {'arguments': '{\"query\": \"Current IPL champions\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_lfY1OrCluBHCjQlCaWw7Hlcv', 'function': {'arguments': '{\"query\": \"Favourites for IPL 2022\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_dME6cFdKRy1YqKhCC9rqYeSG', 'function': {'arguments': '{\"query\": \"Playing eleven for IPL defending champions\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 176, 'total_tokens': 280, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b41f23c5-7a7b-404d-ad74-30126b5709b1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Number of IPL teams'}, 'id': 'call_ZIbUWbZlnEeUPqtH5dyQdzDc', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Current IPL champions'}, 'id': 'call_QeLQG2Q5nD19Mi3kVumivsfC', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Favourites for IPL 2022'}, 'id': 'call_lfY1OrCluBHCjQlCaWw7Hlcv', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Playing eleven for IPL defending champions'}, 'id': 'call_dME6cFdKRy1YqKhCC9rqYeSG', 'type': 'tool_call'}], usage_metadata={'input_tokens': 176, 'output_tokens': 104, 'total_tokens': 280, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'thread_id': '2', 'step': 1, 'parents': {}}, created_at='2025-03-14T22:00:56.198828+00:00', parent_config={'configurable': {'thread_id': '2', 'checkpoint_ns': '', 'checkpoint_id': '1f0011fc-d731-636d-8000-1a73a7c560af'}}, tasks=(PregelTask(id='297a5041-27be-5e7c-8d13-c289c08f7e98', name='action', path=('__pregel_pull', 'action'), error=None, interrupts=(), state=None, result=None),))\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\":{\"thread_id\":\"2\"}}\n",
    "for event in abot.graph.stream({\"messages\":messages}, thread):\n",
    "    for v in event.values():\n",
    "        print (v)\n",
    "while abot.graph.get_state(thread).next:\n",
    "    print (abot.graph.get_state(thread))\n",
    "    _input = input(\"proceed?: \")\n",
    "    if _input != 'y':\n",
    "        print (\"aborting...\")\n",
    "        break\n",
    "    else:\n",
    "        for event in abot.graph.stream(None, thread):\n",
    "            for v in event.values():\n",
    "                print (v)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
